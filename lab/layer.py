# #receptor 0
                    # receptor([200, 200], pygame.K_w),
                    # #receptor 1
                    # receptor([200, 400], pygame.K_q),
                    
                    # #neuron 0
                    # neuron([400, 200], [[0, 1, 1]], [], 1, 1, 5, 0),
                    # #neuron 1
                    # neuron([400, 400], [[1, 1, 1]], [], 1, 1, 5, 0),
                    # #neuron 2
                    # neuron([600, 200], [[2, 1, 1], [3, -1, 1]], [], 1, 1, 5, 0),
                    # #neuron 3
                    # neuron([600, 400], [[3, 1, 1], [2, -1, 1]], [], 1, 1, 5, 0),
                    # #neuron 4
                    # neuron([800, 300], [[4, 1, 1], [5, 1, 1]], [], 1, 1, 5, 0)

import math as m
from nodes import Glia, Receptor, Neuron

class Layer():
    #set up for a test
    #MAJOR
        #TODO: have these generated by a factory which is updated by the run
    #learning algorithm
        #TODO: realistic back prop: based on LTP/LTD (simulate channels?)
            #synapse generation: after neuron fires it enters receptive period; sensing subsequent firing: growing excit to fired, inhib to non fired.
            #(?) nodes are spatially represented?
            #(?) synapse growth is assocaited with cost
            #(?) synapses are pruned?
            #(?) synapses are grown with a vote system which only connects a synapse after a threshold of votes
        #BENCHMARK: XOR gate
    #interacting
        # TODO: synapses can be added through runtime interaction
        # TODO: all nodes can be moved during runtime interaction
        # TODO: comment EVERYTHING
        # TODO: maybe streamline the decleration/storage of these variables
    
    def __init__(self, dimensions, node_params, layer_params):
        # probs get rid of rows lol >:(
        self.layer = [Neuron([i+1, j+1], [], [], [], 
                        node_params['base_threshold'], 
                        node_params['leak'], 
                        node_params['refractory'],
                        node_params['duty_period'])
                        for i in range(dimensions[0])
                        for j in range(dimensions[1])]

        self.layer_size = dimensions[0] * dimensions[1]

        self.layer_params = layer_params

    def layer_active_nodes(self):
        _active_nodes = []

        for n in self.layer:
            if n.is_active:
                _active_nodes.append(n)

        return _active_nodes

    def update_distal_synapses(self):
        for post_n in self.layer:
            for d_syn in post_n.d_synapses:
                if post_n.is_active:

                    if d_syn[0].was_active:
                        if d_syn[1] == 1:
                            d_syn[2] += self.layer_params['dist_excit_incr']
                            d_syn[2] = min([d_syn[2] ,self.layer_params['dist_excit_max']])
                        else:
                            d_syn[2] -= self.layer_params['dist_inhib_decr']
                            d_syn[2] = max([d_syn[2], 0]) 
                    
                    else:
                        if d_syn[1] == 1:
                            d_syn[2] -= self.layer_params['dist_excit_decr']
                            d_syn[2] = max([d_syn[2], 0])
                        else:
                            d_syn[2] += self.layer_params['dist_inhib_incr']
                            d_syn[2] = min([d_syn[2], self.layer_params['dist_inhib_max']])
                else:
                    if d_syn[0].was_active:
                        if d_syn[1] == 1:
                            d_syn[2] -= self.layer_params['dist_excit_decr']
                            d_syn[2] = max([d_syn[2], 0])
                        else:
                            d_syn[2] += self.layer_params['dist_inhib_incr']
                            d_syn[2] = min([d_syn[2], self.layer_params['dist_inhib_max']])

        